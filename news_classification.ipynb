{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# $\\textbf{Atelier: NEWS-Classification}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\textbf{1. Objectif : }$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L’objectif de cet atelier est de découvrir la classification de documents texte à travers le classificateur SVM que nous allons appliquer sur un dataset contenant les news apparus sur le fil de presse Reuters en 1987.\n",
    "\n",
    "Le datset peut être téléchargé à partir de ce lien : https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /home/alain/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le dataset est disponible également sur scikitlearn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\textbf{2.\tChargement des données }$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous considerons le dataset reuters à partir de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "#recuperation du vocabulaire du corpus\n",
    "vocabulaire=reuters.words()\n",
    "\n",
    "#recuperation de toutes les categories\n",
    "categories=reuters.categories()\n",
    "\n",
    "#recuperation de tous les id des fichiers appartenant à une categorie bien determinée\n",
    "ids_coffe=reuters.fileids(\"coffee\")\n",
    "\n",
    "#recuperation des mots contenus dans les documents d'une categorie bien determinee\n",
    "coffe_words=reuters.words(reuters.fileids(\"coffee\"))\n",
    "\n",
    "#recuperation du texte brut des documents d'une categorie bien determinee\n",
    "cofee_docs=reuters.raw(reuters.fileids(\"coffee\")[0])\n",
    "\n",
    "#recuperation de toutes les autres classe d'un document annoté avec une classe bien determinee\n",
    "classes_Annotated_coffee=reuters.categories(reuters.fileids(\"coffee\"))\n",
    "\n",
    "#recuperer le dataset d'apprentissage\n",
    "train_categories=[ reuters.categories(i) for i in reuters.fileids() if i.startswith('training/')]\n",
    "train_documents = [reuters.raw(i) for i in reuters.fileids() if i.startswith('training/')]\n",
    "\n",
    "#recuperer le dataset de test\n",
    "test_documents=[reuters.raw(i)  for i in reuters.fileids() if i.startswith('test/')]\n",
    "test_categories = [reuters.categories(i) for i in reuters.fileids() if i.startswith('test/')]\n",
    "\n",
    "# recuperer tout le corpus\n",
    "whole_docs=[reuters.raw(i)for i in reuters.fileids()]\n",
    "whole_cats = [ reuters.categories(i) for i in reuters.fileids()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\textbf{\n",
    "3.\tPrétraitements }$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{\n",
    "Récupération des représentations vectorielles en TF-IDF}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10788, 90)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "#fit(raw_documents[, y]): Learn vocabulary and idf from training set.\n",
    "#fit_transform(raw_documents[, y]): Learn vocabulary and idf, return document-term matrix.\n",
    "#transform(raw_documents): Transform documents to document-term matrix.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "vect_whole_docs = vectorizer.fit_transform(whole_docs)\n",
    "vect_train_docs = vectorizer.transform(train_documents)\n",
    "vect_test_docs = vectorizer.transform(test_documents)\n",
    "\n",
    "#recuperer des labels uniques pour les categories\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "train_labels = mlb.fit_transform(train_categories)\n",
    "test_labels = mlb.transform(test_categories)\n",
    "whole_labels = mlb.fit_transform(whole_cats)\n",
    "\n",
    "print(whole_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10788, 30627)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_whole_docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\textbf{\n",
    "4.\tClassification avec SVM}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       719\n",
      "           1       1.00      0.43      0.61        23\n",
      "           2       1.00      0.64      0.78        14\n",
      "           3       0.95      0.60      0.73        30\n",
      "           4       0.88      0.39      0.54        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.94      0.97        18\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.96      0.96      0.96        28\n",
      "          10       1.00      0.78      0.88        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.95      0.71      0.82        56\n",
      "          13       1.00      0.50      0.67        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.92      0.43      0.59        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.91      0.81      0.86       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.85      0.66      0.74        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.99      0.98      0.99      1087\n",
      "          22       1.00      0.20      0.33        10\n",
      "          23       1.00      0.53      0.69        17\n",
      "          24       1.00      0.80      0.89        35\n",
      "          25       0.92      0.73      0.81        30\n",
      "          26       0.98      0.81      0.89       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.60      0.75         5\n",
      "          30       1.00      0.33      0.50         6\n",
      "          31       1.00      0.75      0.86         4\n",
      "          32       1.00      0.43      0.60         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.88      0.66      0.75       131\n",
      "          35       1.00      0.83      0.91        12\n",
      "          36       0.75      0.64      0.69        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.92      0.57      0.71        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.69      0.38      0.49        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       1.00      0.16      0.27        19\n",
      "          46       0.81      0.73      0.76       179\n",
      "          47       0.89      0.74      0.81        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.74      0.47      0.57        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       1.00      0.17      0.29         6\n",
      "          54       0.79      0.47      0.59        47\n",
      "          55       1.00      0.45      0.62        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      0.60      0.75        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       1.00      0.33      0.50         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.44      0.62         9\n",
      "          66       0.91      0.56      0.69        18\n",
      "          67       1.00      0.50      0.67         2\n",
      "          68       0.88      0.29      0.44        24\n",
      "          69       1.00      0.75      0.86        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.89      0.63      0.74        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       0.75      0.30      0.43        10\n",
      "          74       1.00      0.15      0.27        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.83      0.45      0.59        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       0.96      0.72      0.83        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       1.00      0.20      0.33         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       1.00      0.58      0.74        12\n",
      "          84       0.87      0.75      0.81       117\n",
      "          85       0.94      0.43      0.59        37\n",
      "          86       0.93      0.75      0.83        71\n",
      "          87       1.00      0.60      0.75        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       1.00      0.46      0.63        13\n",
      "\n",
      "   micro avg       0.95      0.78      0.86      3744\n",
      "   macro avg       0.59      0.36      0.43      3744\n",
      "weighted avg       0.91      0.78      0.83      3744\n",
      " samples avg       0.87      0.85      0.86      3744\n",
      "\n",
      "0.8042398145081153\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classifier_svm = OneVsRestClassifier(LinearSVC())\n",
    "classifier_svm.fit(vect_train_docs,train_labels)\n",
    "test_labels_predict=classifier_svm.predict(vect_test_docs)\n",
    "\n",
    "print(classification_report(test_labels,test_labels_predict))\n",
    "scores=classifier_svm.score(vect_test_docs,test_labels)\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\textbf{\n",
    "5.\tClassification  SVM avec cross validation}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.96312261 2.05393624 1.8967886  1.87351632 1.85604215]\n",
      "[0.07709217 0.07549524 0.07638812 0.07514453 0.07815814]\n",
      "[0.8686747  0.88214396 0.8836886  0.89460671 0.89554165]\n",
      "[0.85052207 0.86513196 0.86309211 0.87661217 0.86938649]\n",
      "[0.85113967 0.86563286 0.86497342 0.87832754 0.87432217]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "scoring = ['precision_samples', 'recall_samples', 'f1_samples', 'accuracy']\n",
    "scores_svm = cross_validate(classifier_svm, vect_whole_docs, whole_labels, cv=5, scoring=scoring)\n",
    "print(scores_svm['fit_time'])\n",
    "print(scores_svm['score_time'])\n",
    "print(scores_svm['test_precision_samples'])\n",
    "print(scores_svm['test_recall_samples'])\n",
    "print(scores_svm['test_f1_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8849311228008213\n",
      "0.8649489602866532\n",
      "0.8668791306612522\n",
      "0.8130354734440062\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores_svm['test_precision_samples']))\n",
    "print(np.mean(scores_svm['test_recall_samples']))\n",
    "print(np.mean(scores_svm['test_f1_samples']))\n",
    "print(np.mean(scores_svm['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\textbf{6. Questions}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Réaliser le même processus avec le KNN et comparer les performances obtenues avec SVM.\n",
    "\n",
    "Q2. Réaliser le même processus avec une méthode ensembliste et comparer les performances obtenues avec KNN et SVM.\n",
    "\n",
    "Q3. Realiser les même processus en appliquant un features selection SelectKBest de la librairie sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{KNN, SVM }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.728055647565419\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Classification avec le KNN\"\"\"\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "    \n",
    "classifier_knn = OneVsRestClassifier(KNeighborsClassifier())\n",
    "classifier_knn.fit(vect_train_docs, train_labels)\n",
    "test_labels_predict = classifier_knn.predict(vect_test_docs)\n",
    "\n",
    "#print(classification_report(test_labels,test_labels_predict))\n",
    "scores = classifier_knn.score(vect_test_docs, test_labels)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.80       719\n",
      "           1       0.77      0.43      0.56        23\n",
      "           2       0.86      0.43      0.57        14\n",
      "           3       0.62      0.53      0.57        30\n",
      "           4       0.73      0.61      0.67        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.94      0.97        18\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.83      0.89      0.86        28\n",
      "          10       0.74      0.78      0.76        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.70      0.59      0.64        56\n",
      "          13       0.82      0.45      0.58        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.82      0.50      0.62        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.81      0.90      0.85       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.75      0.68      0.71        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.88      0.96      0.92      1087\n",
      "          22       0.50      0.20      0.29        10\n",
      "          23       1.00      0.41      0.58        17\n",
      "          24       0.81      0.71      0.76        35\n",
      "          25       0.91      0.67      0.77        30\n",
      "          26       0.83      0.80      0.82       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.60      0.75         5\n",
      "          30       1.00      0.50      0.67         6\n",
      "          31       0.50      0.75      0.60         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       1.00      1.00      1.00         1\n",
      "          34       0.81      0.66      0.73       131\n",
      "          35       1.00      0.83      0.91        12\n",
      "          36       0.92      0.79      0.85        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.52      0.69        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       1.00      0.14      0.25        14\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.71      0.71      0.71        24\n",
      "          44       1.00      0.17      0.29         6\n",
      "          45       0.75      0.16      0.26        19\n",
      "          46       0.72      0.84      0.77       179\n",
      "          47       0.74      0.82      0.78        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.75      0.50      0.60        30\n",
      "          50       1.00      1.00      1.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.64      0.34      0.44        47\n",
      "          55       1.00      0.64      0.78        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.88      0.70      0.78        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       1.00      0.08      0.15        12\n",
      "          60       1.00      0.29      0.44         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.44      0.62         9\n",
      "          66       0.67      0.44      0.53        18\n",
      "          67       1.00      0.50      0.67         2\n",
      "          68       0.50      0.08      0.14        24\n",
      "          69       0.82      0.75      0.78        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.76      0.74      0.75        89\n",
      "          72       0.67      0.25      0.36         8\n",
      "          73       0.25      0.10      0.14        10\n",
      "          74       1.00      0.08      0.14        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.75      0.36      0.49        33\n",
      "          77       1.00      0.09      0.17        11\n",
      "          78       0.96      0.72      0.83        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.50      0.20      0.29         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       1.00      0.75      0.86        12\n",
      "          84       0.70      0.67      0.68       117\n",
      "          85       0.72      0.49      0.58        37\n",
      "          86       0.62      0.75      0.68        71\n",
      "          87       1.00      0.60      0.75        10\n",
      "          88       0.60      0.21      0.32        14\n",
      "          89       1.00      0.31      0.47        13\n",
      "\n",
      "   micro avg       0.84      0.73      0.78      3744\n",
      "   macro avg       0.57      0.39      0.43      3744\n",
      "weighted avg       0.82      0.73      0.76      3744\n",
      " samples avg       0.80      0.80      0.79      3744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_labels_predict = classifier_knn.predict(vect_test_docs)\n",
    "print(classification_report(test_labels,test_labels_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM donne un meilleur score que le KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94       719\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       1.00      0.07      0.13        14\n",
      "           3       1.00      0.03      0.06        30\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       1.00      0.29      0.44        28\n",
      "          10       1.00      0.06      0.11        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      0.23      0.38        56\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.80      0.14      0.24        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.98      0.64      0.78       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.91      0.23      0.36        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       1.00      0.96      0.98      1087\n",
      "          22       0.00      0.00      0.00        10\n",
      "          23       1.00      0.06      0.11        17\n",
      "          24       1.00      0.03      0.06        35\n",
      "          25       0.00      0.00      0.00        30\n",
      "          26       0.93      0.66      0.77       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.20      0.33         5\n",
      "          30       1.00      0.33      0.50         6\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.92      0.37      0.53       131\n",
      "          35       1.00      0.08      0.15        12\n",
      "          36       0.00      0.00      0.00        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.10      0.17        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       1.00      0.12      0.22        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.82      0.47      0.60       179\n",
      "          47       0.86      0.35      0.50        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       1.00      0.17      0.29         6\n",
      "          54       0.91      0.21      0.34        47\n",
      "          55       1.00      0.09      0.17        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.33      0.50         9\n",
      "          66       1.00      0.06      0.11        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00        24\n",
      "          69       0.00      0.00      0.00        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.93      0.30      0.46        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       1.00      0.10      0.18        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       1.00      0.03      0.06        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       1.00      0.11      0.20        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       0.00      0.00      0.00        12\n",
      "          84       0.94      0.29      0.44       117\n",
      "          85       1.00      0.11      0.20        37\n",
      "          86       0.92      0.31      0.46        71\n",
      "          87       0.00      0.00      0.00        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.97      0.60      0.74      3744\n",
      "   macro avg       0.35      0.09      0.13      3744\n",
      "weighted avg       0.85      0.60      0.65      3744\n",
      " samples avg       0.71      0.68      0.69      3744\n",
      "\n",
      "0.6531964226565088\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Classification avec RandomForestClassifier\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    \n",
    "classifier_rf = OneVsRestClassifier(RandomForestClassifier())\n",
    "classifier_rf.fit(vect_train_docs, train_labels)\n",
    "test_labels_predict = classifier_rf.predict(vect_test_docs)\n",
    "\n",
    "print(classification_report(test_labels,test_labels_predict))\n",
    "scores = classifier_rf.score(vect_test_docs, test_labels)\n",
    "print(scores)\n",
    "\n",
    "# Use here RandomForest selector, best covariates,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Classification avec RandomForestClassifier\"\"\"\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classifier_ada = OneVsRestClassifier(AdaBoostClassifier())\n",
    "classifier_ada.fit(vect_train_docs, train_labels)\n",
    "test_labels_predict = classifier_ada.predict(vect_test_docs)\n",
    "\n",
    "scores = classifier_ada.score(vect_test_docs, test_labels)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_predict = classifier_ada.predict(vect_test_docs)\n",
    "print(classification_report(test_labels,test_labels_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " SVM reste meilleur que le KNN et les forêts aléatoires(RandomForestClassifier) et AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{SelectKBest}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10788, 30627), (10788, 90))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_whole_docs.shape, whole_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Selection de 5% des variables indépendantes}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69789314 0.90614653 0.71261907 0.8198657  0.75821567]\n",
      "[0.0524838  0.06912756 0.05868912 0.07013392 0.05280447]\n",
      "[0.85911338 0.8699413  0.85641026 0.86957194 0.86077113]\n",
      "[0.84411696 0.85885299 0.83879364 0.85703602 0.84128419]\n",
      "[0.8432317  0.85583085 0.8389015  0.85572424 0.8432789 ] \n",
      "\n",
      "0.8631616011494356\n",
      "0.8480167604692965\n",
      "0.847393438957688\n",
      "0.7903236783659726\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=1531).fit_transform(vect_whole_docs, whole_labels)\n",
    "\n",
    "scoring = ['precision_samples', 'recall_samples', 'f1_samples', 'accuracy']\n",
    "scores_svm = cross_validate(classifier_svm, X_new, whole_labels, cv=5, scoring=scoring)\n",
    "\n",
    "print(scores_svm['fit_time'])\n",
    "print(scores_svm['score_time'])\n",
    "print(scores_svm['test_precision_samples'])\n",
    "print(scores_svm['test_recall_samples'])\n",
    "print(scores_svm['test_f1_samples'], \"\\n\")\n",
    "\n",
    "print(np.mean(scores_svm['test_precision_samples']))\n",
    "print(np.mean(scores_svm['test_recall_samples']))\n",
    "print(np.mean(scores_svm['test_f1_samples']))\n",
    "print(np.mean(scores_svm['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Selection de 10% des variables indépendantes}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99409676 0.9782083  0.92197371 0.91986752 0.84991503]\n",
      "[0.0640173  0.07003403 0.06291127 0.05480576 0.07793283]\n",
      "[0.8718721  0.8853877  0.87546339 0.88842528 0.88715809]\n",
      "[0.85626114 0.8705382  0.85600994 0.87395767 0.86444908]\n",
      "[0.85581149 0.87000419 0.85718954 0.87428618 0.86749795] \n",
      "\n",
      "0.8816613144923047\n",
      "0.8642432053727443\n",
      "0.8649578693150837\n",
      "0.8096977618401281\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=3062).fit_transform(vect_whole_docs, whole_labels)\n",
    "\n",
    "scoring = ['precision_samples', 'recall_samples', 'f1_samples', 'accuracy']\n",
    "scores_svm = cross_validate(classifier_svm, X_new, whole_labels, cv=5, scoring=scoring)\n",
    "\n",
    "print(scores_svm['fit_time'])\n",
    "print(scores_svm['score_time'])\n",
    "print(scores_svm['test_precision_samples'])\n",
    "print(scores_svm['test_recall_samples'])\n",
    "print(scores_svm['test_f1_samples'], \"\\n\")\n",
    "\n",
    "print(np.mean(scores_svm['test_precision_samples']))\n",
    "print(np.mean(scores_svm['test_recall_samples']))\n",
    "print(np.mean(scores_svm['test_f1_samples']))\n",
    "print(np.mean(scores_svm['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Selection de 15% des variables indépendantes}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.08230186 1.03436089 1.01106167 0.96012235 0.92841911]\n",
      "[0.05676699 0.0741477  0.08689499 0.06278205 0.05581307]\n",
      "[0.86837349 0.88809082 0.87855267 0.89360223 0.89175552]\n",
      "[0.85430366 0.87173529 0.85813382 0.87873282 0.8689847 ]\n",
      "[0.85327828 0.87184231 0.8596413  0.87904808 0.87221349] \n",
      "\n",
      "0.8840749482004908\n",
      "0.8663780587876555\n",
      "0.8672046944941944\n",
      "0.8115520174202748\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=4594).fit_transform(vect_whole_docs, whole_labels)\n",
    "\n",
    "scoring = ['precision_samples', 'recall_samples', 'f1_samples', 'accuracy']\n",
    "scores_svm = cross_validate(classifier_svm, X_new, whole_labels, cv=5, scoring=scoring)\n",
    "\n",
    "print(scores_svm['fit_time'])\n",
    "print(scores_svm['score_time'])\n",
    "print(scores_svm['test_precision_samples'])\n",
    "print(scores_svm['test_recall_samples'])\n",
    "print(scores_svm['test_f1_samples'], \"\\n\")\n",
    "\n",
    "print(np.mean(scores_svm['test_precision_samples']))\n",
    "print(np.mean(scores_svm['test_recall_samples']))\n",
    "print(np.mean(scores_svm['test_f1_samples']))\n",
    "print(np.mean(scores_svm['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24561357 0.29466677 0.24288511 0.24265838 0.34293342]\n",
      "[81.04196477 76.25177646 73.68394494 79.26062226 80.26495886]\n",
      "[0.69176707 0.72265987 0.68534137 0.71743162 0.71076341]\n",
      "[0.68595812 0.715378   0.67926063 0.7110699  0.69702519]\n",
      "[0.68558593 0.71483811 0.67905946 0.71065002 0.69924257] \n",
      "\n",
      "0.7055926655876384\n",
      "0.6977383673753298\n",
      "0.697875219440144\n",
      "0.6694483508013008\n"
     ]
    }
   ],
   "source": [
    "\"\"\" KNN Classifier \"\"\"\n",
    "\n",
    "X_new = SelectKBest(chi2, k=4594).fit_transform(vect_whole_docs, whole_labels)\n",
    "\n",
    "scoring = ['precision_samples', 'recall_samples', 'f1_samples', 'accuracy']\n",
    "classifier_knn = OneVsRestClassifier(KNeighborsClassifier())\n",
    "classifier_knn = cross_validate(classifier_knn, X_new, whole_labels, cv=5, scoring=scoring)\n",
    "\n",
    "print(classifier_knn['fit_time'])\n",
    "print(classifier_knn['score_time'])\n",
    "print(classifier_knn['test_precision_samples'])\n",
    "print(classifier_knn['test_recall_samples'])\n",
    "print(classifier_knn['test_f1_samples'], \"\\n\")\n",
    "\n",
    "print(np.mean(classifier_knn['test_precision_samples']))\n",
    "print(np.mean(classifier_knn['test_recall_samples']))\n",
    "print(np.mean(classifier_knn['test_f1_samples']))\n",
    "print(np.mean(classifier_knn['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110.49026394 118.3114078  113.67388725 109.51805329 113.13453937]\n",
      "[3.54869795 3.43697834 3.14020848 2.99070048 3.02524662]\n",
      "[0.7713701  0.81093605 0.77527804 0.79578118 0.79103693]\n",
      "[0.74215415 0.77819961 0.74292555 0.76878143 0.75970484]\n",
      "[0.74842083 0.78528951 0.75010767 0.77521302 0.76671045] \n",
      "\n",
      "0.7888804588920211\n",
      "0.7583531148881703\n",
      "0.7651482969051553\n",
      "0.712552617660113\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Rf Classifier \"\"\"\n",
    "\n",
    "X_new = SelectKBest(chi2, k=4594).fit_transform(vect_whole_docs, whole_labels)\n",
    "\n",
    "scoring = ['precision_samples', 'recall_samples', 'f1_samples', 'accuracy']\n",
    "classifier_rf = OneVsRestClassifier(RandomForestClassifier())\n",
    "classifier_rf = cross_validate(classifier_rf, X_new, whole_labels, cv=5, scoring=scoring)\n",
    "\n",
    "print(classifier_rf['fit_time'])\n",
    "print(classifier_rf['score_time'])\n",
    "print(classifier_rf['test_precision_samples'])\n",
    "print(classifier_rf['test_recall_samples'])\n",
    "print(classifier_rf['test_f1_samples'], \"\\n\")\n",
    "\n",
    "print(np.mean(classifier_rf['test_precision_samples']))\n",
    "print(np.mean(classifier_rf['test_recall_samples']))\n",
    "print(np.mean(classifier_rf['test_f1_samples']))\n",
    "print(np.mean(classifier_rf['test_accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Conclusion : SVM }$  donne les meilleurs résultats(meilleures valeurs de métrique)(validation croisée) que les autres algorithmes testés dans cet atelier sur $15\\%$ des variables indépendantes comme sur l'ensemble des variables indépendantes, même en temps d'exécution. Ainsi, $15\\%$ des variables indépendantes suffiront."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
